# Classifica√ß√£o de Tipos de Solo com Transfer Learning (PyTorch)

Este projeto aplica t√©cnicas de **Deep Learning** e **Transfer Learning** para classificar diferentes tipos de solo a partir de imagens. O c√≥digo utiliza a biblioteca **PyTorch** para treinar e avaliar dois modelos de arquiteturas consagradas: **AlexNet** e **ResNet18**.

## üìå Sobre o Projeto

O objetivo deste notebook √© criar um classificador de imagens capaz de identificar 7 tipos diferentes de solos, auxiliando em an√°lises agr√≠colas e geol√≥gicas. O projeto utiliza uma abordagem de *Hold-out* para divis√£o dos dados e *Transfer Learning* (congelamento de pesos das camadas convolucionais) para adaptar modelos pr√©-treinados ao novo dataset.

## üìÇ Dataset

O conjunto de dados utilizado √© o **Comprehensive Soil Classification Dataset**, obtido via API do Kaggle.

* **Fonte:** [Kaggle - Comprehensive Soil Classification Datasets](https://www.kaggle.com/datasets/ai4a-lab/comprehensive-soil-classification-datasets)
* **Classes (7 tipos):**
    * Alluvial_Soil (Solo Aluvial)
    * Arid_Soil (Solo √Årido)
    * Black_Soil (Solo Preto)
    * Laterite_Soil (Solo Later√≠tico)
    * Mountain_Soil (Solo de Montanha)
    * Red_Soil (Solo Vermelho)
    * Yellow_Soil (Solo Amarelo)

## üõ†Ô∏è Tecnologias e Bibliotecas

* **Linguagem:** Python 3
* **Framework de DL:** PyTorch, Torchvision
* **Processamento de Dados:** Numpy, PIL (Pillow), Glob
* **M√©tricas e Split:** Scikit-learn
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Ambiente:** Google Colab

## üß† Metodologia

1.  **Prepara√ß√£o dos Dados:**
    * Download autom√°tico via Kaggle API.
    * Divis√£o dos dados: Treino (60%), Valida√ß√£o (20%) e Teste (20%).
    * **Transforma√ß√µes:** Redimensionamento para 224x224, *Data Augmentation* (RandomHorizontalFlip) para o treino e Normaliza√ß√£o (baseada nas m√©dias da ImageNet).

2.  **Arquiteturas de Modelos:**
    * **AlexNet:** Pr√©-treinada. Camadas de *features* congeladas. Camada final ajustada para 7 sa√≠das.
    * **ResNet18:** Pr√©-treinada. Par√¢metros congelados. Camada `fc` (fully connected) substitu√≠da.

3.  **Treinamento:**
    * **Fun√ß√£o de Perda:** CrossEntropyLoss.
    * **Otimizador:** SGD (Stochastic Gradient Descent) com Momentum.
    * **√âpocas:** 50 √©pocas para cada modelo.
    * **Batch Size:** 32.

## üìä Resultados

Abaixo est√£o as m√©tricas obtidas na avalia√ß√£o do conjunto de teste (dados nunca vistos pelo modelo durante o treino):

| Modelo | Acur√°cia no Teste | Melhor Acur√°cia (Valida√ß√£o) |
| :--- | :---: | :---: |
| **AlexNet** | **86.55%** | 90.72% |
| **ResNet18** | 82.35% | 85.23% |

### Performance por Classe (Exemplo AlexNet)
O modelo obteve excelente desempenho em solos como **Black_Soil (F1: 0.98)** e **Yellow_Soil (F1: 0.89)**, mas apresentou maior dificuldade em distinguir **Alluvial_Soil**.

## üöÄ Como Executar

1.  Clone este reposit√≥rio.
2.  Certifique-se de ter uma conta no Kaggle e um token de API (`kaggle.json`).
3.  Abra o notebook no Google Colab ou Jupyter Notebook local.
4.  Instale as depend√™ncias necess√°rias:
    ```bash
    pip install torch torchvision scikit-learn matplotlib seaborn
    ```
5.  Carregue o arquivo `kaggle.json` quando solicitado na primeira c√©lula para baixar o dataset.
6.  Execute as c√©lulas sequencialmente.

## üìà Visualiza√ß√µes

O notebook gera os seguintes gr√°ficos para an√°lise:
* Curvas de Loss (Treino vs Valida√ß√£o).
* Curvas de Acur√°cia (Treino vs Valida√ß√£o).
* Matriz de Confus√£o (Heatmap) para an√°lise de erros entre classes.

---
*Desenvolvido como parte de estudos em Vis√£o Computacional e Deep Learning.*